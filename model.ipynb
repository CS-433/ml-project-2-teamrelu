{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1 : simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37100/1826048385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def _init_(self, input_size=320, num_classes=25):\n",
    "        super(SimpleClassifier, self)._init_()\n",
    "        \n",
    "        self.inner = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  # First layer, reduces to 128 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),        # Second layer, reduces to 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes), # Output layer, 25 classes\n",
    "            # Sigmoid for the output\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.inner(x)\n",
    "\n",
    "# Create the model\n",
    "input_size = 320\n",
    "num_classes = 25\n",
    "model = SimpleClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model = lambda x: nn.Sequential(\n",
    "            nn.Linear(x, 128),  # First layer, reduces to 128 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),        # Second layer, reduces to 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 25), # Output layer, 25 classes\n",
    "            # Sigmoid for the output\n",
    "            nn.Sigmoid()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/emilia_farina/ml-project-2-teamrelu/static_proteins_embeddings (1).csv'\n",
    "data_ = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>320</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAL005C</td>\n",
       "      <td>-0.147314</td>\n",
       "      <td>-0.012922</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.187505</td>\n",
       "      <td>0.219922</td>\n",
       "      <td>0.085134</td>\n",
       "      <td>0.219985</td>\n",
       "      <td>-0.062393</td>\n",
       "      <td>-0.117973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.058976</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.246687</td>\n",
       "      <td>0.085420</td>\n",
       "      <td>-0.279169</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>0.110163</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>-0.060808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAL007C</td>\n",
       "      <td>-0.137761</td>\n",
       "      <td>0.093442</td>\n",
       "      <td>0.148724</td>\n",
       "      <td>0.068417</td>\n",
       "      <td>0.196473</td>\n",
       "      <td>-0.019563</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>-0.034252</td>\n",
       "      <td>-0.009316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>0.128978</td>\n",
       "      <td>0.079171</td>\n",
       "      <td>-0.041726</td>\n",
       "      <td>-0.017028</td>\n",
       "      <td>-0.202261</td>\n",
       "      <td>-0.133137</td>\n",
       "      <td>0.102420</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>0.017614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAL008W</td>\n",
       "      <td>0.100238</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>0.267723</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>-0.168686</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072495</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>-0.004583</td>\n",
       "      <td>0.031956</td>\n",
       "      <td>-0.027646</td>\n",
       "      <td>-0.137027</td>\n",
       "      <td>-0.255539</td>\n",
       "      <td>0.074986</td>\n",
       "      <td>-0.087161</td>\n",
       "      <td>0.214416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAL009W</td>\n",
       "      <td>-0.017027</td>\n",
       "      <td>0.064426</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.084343</td>\n",
       "      <td>0.127024</td>\n",
       "      <td>-0.108611</td>\n",
       "      <td>-0.069318</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.104692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038916</td>\n",
       "      <td>-0.067139</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.123670</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>-0.080713</td>\n",
       "      <td>-0.096557</td>\n",
       "      <td>0.193680</td>\n",
       "      <td>-0.024982</td>\n",
       "      <td>0.132274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAL010C</td>\n",
       "      <td>-0.258388</td>\n",
       "      <td>-0.097993</td>\n",
       "      <td>0.134574</td>\n",
       "      <td>-0.067857</td>\n",
       "      <td>0.222240</td>\n",
       "      <td>-0.212508</td>\n",
       "      <td>0.181795</td>\n",
       "      <td>0.048118</td>\n",
       "      <td>0.117677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057731</td>\n",
       "      <td>-0.049099</td>\n",
       "      <td>0.178214</td>\n",
       "      <td>0.057316</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>-0.028376</td>\n",
       "      <td>-0.116114</td>\n",
       "      <td>0.115063</td>\n",
       "      <td>-0.181005</td>\n",
       "      <td>0.140581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>YBL103C</td>\n",
       "      <td>-0.009562</td>\n",
       "      <td>-0.133265</td>\n",
       "      <td>-0.065504</td>\n",
       "      <td>-0.134947</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>-0.231709</td>\n",
       "      <td>-0.046263</td>\n",
       "      <td>0.210778</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093705</td>\n",
       "      <td>-0.128606</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>0.248409</td>\n",
       "      <td>0.065048</td>\n",
       "      <td>0.114244</td>\n",
       "      <td>-0.107951</td>\n",
       "      <td>0.485081</td>\n",
       "      <td>-0.330004</td>\n",
       "      <td>-0.107667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>YBL107C</td>\n",
       "      <td>-0.112306</td>\n",
       "      <td>-0.168828</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.130812</td>\n",
       "      <td>0.029688</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>0.135250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133758</td>\n",
       "      <td>-0.029844</td>\n",
       "      <td>0.137266</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>0.044282</td>\n",
       "      <td>-0.057809</td>\n",
       "      <td>-0.146596</td>\n",
       "      <td>0.065237</td>\n",
       "      <td>-0.051147</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>YBL111C</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.184098</td>\n",
       "      <td>0.063246</td>\n",
       "      <td>0.137677</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>-0.119282</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.076206</td>\n",
       "      <td>-0.190447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062111</td>\n",
       "      <td>-0.136090</td>\n",
       "      <td>0.086669</td>\n",
       "      <td>0.045025</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.026630</td>\n",
       "      <td>-0.037882</td>\n",
       "      <td>0.038766</td>\n",
       "      <td>0.101558</td>\n",
       "      <td>0.103943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>YBR001C</td>\n",
       "      <td>0.054988</td>\n",
       "      <td>-0.090878</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.233151</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>-0.090099</td>\n",
       "      <td>-0.118460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>-0.071763</td>\n",
       "      <td>-0.012062</td>\n",
       "      <td>-0.039728</td>\n",
       "      <td>0.103599</td>\n",
       "      <td>-0.074357</td>\n",
       "      <td>-0.090406</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.058768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>YBR002C</td>\n",
       "      <td>-0.084480</td>\n",
       "      <td>-0.089355</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.116330</td>\n",
       "      <td>0.099393</td>\n",
       "      <td>-0.168297</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>-0.102200</td>\n",
       "      <td>-0.135557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.024627</td>\n",
       "      <td>0.102071</td>\n",
       "      <td>-0.032512</td>\n",
       "      <td>0.115510</td>\n",
       "      <td>0.055976</td>\n",
       "      <td>-0.039689</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.097974</td>\n",
       "      <td>-0.004340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    protein1         1         2         3         4         5         6  \\\n",
       "0    YAL005C -0.147314 -0.012922  0.068244  0.187505  0.219922  0.085134   \n",
       "1    YAL007C -0.137761  0.093442  0.148724  0.068417  0.196473 -0.019563   \n",
       "2    YAL008W  0.100238  0.094843  0.240304  0.267723  0.034363 -0.168686   \n",
       "3    YAL009W -0.017027  0.064426  0.017774  0.084343  0.127024 -0.108611   \n",
       "4    YAL010C -0.258388 -0.097993  0.134574 -0.067857  0.222240 -0.212508   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "110  YBL103C -0.009562 -0.133265 -0.065504 -0.134947  0.238506 -0.231709   \n",
       "111  YBL107C -0.112306 -0.168828  0.153530  0.130812  0.029688  0.035168   \n",
       "112  YBL111C -0.024377 -0.184098  0.063246  0.137677  0.073860 -0.119282   \n",
       "113  YBR001C  0.054988 -0.090878  0.018077  0.134946  0.233151 -0.191406   \n",
       "114  YBR002C -0.084480 -0.089355  0.004661  0.116330  0.099393 -0.168297   \n",
       "\n",
       "            7         8         9  ...       311       312       313  \\\n",
       "0    0.219985 -0.062393 -0.117973  ...  0.200829 -0.058976  0.020371   \n",
       "1    0.136663 -0.034252 -0.009316  ...  0.021041  0.128978  0.079171   \n",
       "2    0.074328  0.009313  0.041079  ...  0.072495  0.037649 -0.004583   \n",
       "3   -0.069318 -0.005150 -0.104692  ... -0.038916 -0.067139  0.180053   \n",
       "4    0.181795  0.048118  0.117677  ...  0.057731 -0.049099  0.178214   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "110 -0.046263  0.210778  0.177030  ... -0.093705 -0.128606  0.102385   \n",
       "111  0.012260 -0.069698  0.135250  ...  0.133758 -0.029844  0.137266   \n",
       "112  0.000704 -0.076206 -0.190447  ...  0.062111 -0.136090  0.086669   \n",
       "113  0.044491 -0.090099 -0.118460  ...  0.050133 -0.071763 -0.012062   \n",
       "114  0.092169 -0.102200 -0.135557  ...  0.063479  0.024627  0.102071   \n",
       "\n",
       "          314       315       316       317       318       319       320  \n",
       "0    0.246687  0.085420 -0.279169  0.030401  0.110163  0.059466 -0.060808  \n",
       "1   -0.041726 -0.017028 -0.202261 -0.133137  0.102420 -0.006289  0.017614  \n",
       "2    0.031956 -0.027646 -0.137027 -0.255539  0.074986 -0.087161  0.214416  \n",
       "3    0.123670  0.065432 -0.080713 -0.096557  0.193680 -0.024982  0.132274  \n",
       "4    0.057316  0.063074 -0.028376 -0.116114  0.115063 -0.181005  0.140581  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "110  0.248409  0.065048  0.114244 -0.107951  0.485081 -0.330004 -0.107667  \n",
       "111  0.025584  0.044282 -0.057809 -0.146596  0.065237 -0.051147  0.059044  \n",
       "112  0.045025  0.038349  0.026630 -0.037882  0.038766  0.101558  0.103943  \n",
       "113 -0.039728  0.103599 -0.074357 -0.090406  0.185304  0.002614  0.058768  \n",
       "114 -0.032512  0.115510  0.055976 -0.039689  0.032816  0.097974 -0.004340  \n",
       "\n",
       "[115 rows x 321 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_not_long = pd.read_csv('/home/emilia_farina/ml-project-2-teamrelu/short_static_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_.merge(static_data_not_long, left_on='protein1', right_on='yORF', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>late Golgi</th>\n",
       "      <th>peroxisome</th>\n",
       "      <th>actin</th>\n",
       "      <th>nucleolus</th>\n",
       "      <th>cytoplasm</th>\n",
       "      <th>ER to Golgi</th>\n",
       "      <th>early Golgi</th>\n",
       "      <th>lipid particle</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>bud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAL005C</td>\n",
       "      <td>-0.147314</td>\n",
       "      <td>-0.012922</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.187505</td>\n",
       "      <td>0.219922</td>\n",
       "      <td>0.085134</td>\n",
       "      <td>0.219985</td>\n",
       "      <td>-0.062393</td>\n",
       "      <td>-0.117973</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAL007C</td>\n",
       "      <td>-0.137761</td>\n",
       "      <td>0.093442</td>\n",
       "      <td>0.148724</td>\n",
       "      <td>0.068417</td>\n",
       "      <td>0.196473</td>\n",
       "      <td>-0.019563</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>-0.034252</td>\n",
       "      <td>-0.009316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAL008W</td>\n",
       "      <td>0.100238</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>0.267723</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>-0.168686</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAL009W</td>\n",
       "      <td>-0.017027</td>\n",
       "      <td>0.064426</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.084343</td>\n",
       "      <td>0.127024</td>\n",
       "      <td>-0.108611</td>\n",
       "      <td>-0.069318</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.104692</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAL010C</td>\n",
       "      <td>-0.258388</td>\n",
       "      <td>-0.097993</td>\n",
       "      <td>0.134574</td>\n",
       "      <td>-0.067857</td>\n",
       "      <td>0.222240</td>\n",
       "      <td>-0.212508</td>\n",
       "      <td>0.181795</td>\n",
       "      <td>0.048118</td>\n",
       "      <td>0.117677</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>YBL103C</td>\n",
       "      <td>-0.009562</td>\n",
       "      <td>-0.133265</td>\n",
       "      <td>-0.065504</td>\n",
       "      <td>-0.134947</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>-0.231709</td>\n",
       "      <td>-0.046263</td>\n",
       "      <td>0.210778</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>YBL107C</td>\n",
       "      <td>-0.112306</td>\n",
       "      <td>-0.168828</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.130812</td>\n",
       "      <td>0.029688</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>0.135250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>YBL111C</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.184098</td>\n",
       "      <td>0.063246</td>\n",
       "      <td>0.137677</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>-0.119282</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.076206</td>\n",
       "      <td>-0.190447</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>YBR001C</td>\n",
       "      <td>0.054988</td>\n",
       "      <td>-0.090878</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.233151</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>-0.090099</td>\n",
       "      <td>-0.118460</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>YBR002C</td>\n",
       "      <td>-0.084480</td>\n",
       "      <td>-0.089355</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.116330</td>\n",
       "      <td>0.099393</td>\n",
       "      <td>-0.168297</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>-0.102200</td>\n",
       "      <td>-0.135557</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    protein1         1         2         3         4         5         6  \\\n",
       "0    YAL005C -0.147314 -0.012922  0.068244  0.187505  0.219922  0.085134   \n",
       "1    YAL007C -0.137761  0.093442  0.148724  0.068417  0.196473 -0.019563   \n",
       "2    YAL008W  0.100238  0.094843  0.240304  0.267723  0.034363 -0.168686   \n",
       "3    YAL009W -0.017027  0.064426  0.017774  0.084343  0.127024 -0.108611   \n",
       "4    YAL010C -0.258388 -0.097993  0.134574 -0.067857  0.222240 -0.212508   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "110  YBL103C -0.009562 -0.133265 -0.065504 -0.134947  0.238506 -0.231709   \n",
       "111  YBL107C -0.112306 -0.168828  0.153530  0.130812  0.029688  0.035168   \n",
       "112  YBL111C -0.024377 -0.184098  0.063246  0.137677  0.073860 -0.119282   \n",
       "113  YBR001C  0.054988 -0.090878  0.018077  0.134946  0.233151 -0.191406   \n",
       "114  YBR002C -0.084480 -0.089355  0.004661  0.116330  0.099393 -0.168297   \n",
       "\n",
       "            7         8         9  ...  late Golgi  peroxisome  actin  \\\n",
       "0    0.219985 -0.062393 -0.117973  ...           0           0      0   \n",
       "1    0.136663 -0.034252 -0.009316  ...           0           0      0   \n",
       "2    0.074328  0.009313  0.041079  ...           0           0      0   \n",
       "3   -0.069318 -0.005150 -0.104692  ...           0           0      0   \n",
       "4    0.181795  0.048118  0.117677  ...           0           0      0   \n",
       "..        ...       ...       ...  ...         ...         ...    ...   \n",
       "110 -0.046263  0.210778  0.177030  ...           0           0      0   \n",
       "111  0.012260 -0.069698  0.135250  ...           0           0      0   \n",
       "112  0.000704 -0.076206 -0.190447  ...           0           0      0   \n",
       "113  0.044491 -0.090099 -0.118460  ...           0           0      0   \n",
       "114  0.092169 -0.102200 -0.135557  ...           0           0      0   \n",
       "\n",
       "     nucleolus  cytoplasm  ER to Golgi  early Golgi  lipid particle  nucleus  \\\n",
       "0            0          1            0            0               0        0   \n",
       "1            0          0            0            0               0        0   \n",
       "2            0          0            0            0               0        0   \n",
       "3            0          0            0            0               0        1   \n",
       "4            0          0            0            0               0        0   \n",
       "..         ...        ...          ...          ...             ...      ...   \n",
       "110          0          1            0            0               0        1   \n",
       "111          0          1            0            0               0        0   \n",
       "112          0          0            0            0               0        0   \n",
       "113          0          1            0            0               0        0   \n",
       "114          0          0            0            0               0        0   \n",
       "\n",
       "     bud  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "..   ...  \n",
       "110    0  \n",
       "111    0  \n",
       "112    0  \n",
       "113    0  \n",
       "114    0  \n",
       "\n",
       "[115 rows x 345 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'first_static.csv'\n",
    "data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    # Conversione in un array numerico di tipo float32\n",
    "    features = np.asarray(self.features[idx], dtype=np.float32)\n",
    "    target = np.asarray(self.targets[idx], dtype=np.float32)\n",
    "\n",
    "    # Conversione in torch.Tensor\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    target = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.features = data.iloc[:, :-1].values  # All columns except the last as features\n",
    "        self.labels = data.iloc[:, -1].values     # The last column as labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert to PyTorch tensors\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_dataset = ProteinDataset(train_data)\n",
    "val_dataset = ProteinDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader():\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset = train_dataset ,\n",
    "        batch_size = 16,\n",
    "        shuffle = True,\n",
    "        num_workers = 2,\n",
    "        pin_memory = torch.cuda.is_available(),\n",
    "        drop_last = False\n",
    "    )\n",
    "    \n",
    "def val_loader():\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset = val_dataset,\n",
    "        batch_size = 16,\n",
    "        shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device, threshold):\n",
    "    # ***************************************************\n",
    "    # ***************************************************\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    lr_history = []\n",
    "    correct_sequences = 0  \n",
    "    partial_scores = []\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_float = loss.item()\n",
    "        pred = (output >= threshold).int()\n",
    "        correct = (pred == target).all(dim=1)\n",
    "        correct_sequences += correct.sum().item()  \n",
    "        partial_accuracy = (pred == target).sum(dim=1).float() / target.size(1) \n",
    "        partial_scores.extend(partial_accuracy.tolist())\n",
    "        exact_accuracy_float = correct / len(data)\n",
    "        loss_history.append(loss_float)\n",
    "        accuracy_history.append(exact_accuracy_float)\n",
    "        weighted_accuracy = sum(partial_scores) / len(partial_scores)\n",
    "\n",
    "        lr_history.append(scheduler.get_last_lr()[0])\n",
    "        if batch_idx % (len(train_loader.dataset) // len(data) // 10) == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch}-{batch_idx:03d} \"\n",
    "                f\"batch_loss={loss_float:0.2e} \"\n",
    "                f\"batch_acc={exact_accuracy_float:0.3f} \"\n",
    "                f\"batch_acc={weighted_accuracy:0.3f} \"\n",
    "                f\"lr={scheduler.get_last_lr()[0]:0.3e} \"\n",
    "            )\n",
    "\n",
    "    return loss_history, accuracy_history, lr_history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, device, val_loader, criterion, threshold):\n",
    "    model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() * len(data)\n",
    "        pred = (output >= threshold).int()\n",
    "        correct = (pred == target).all(dim=1)\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(val_loader.dataset),\n",
    "            100.0 * correct / len(val_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    return test_loss, correct / len(val_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, device, val_loader, criterion, threshold, num=None):\n",
    "    model.eval()\n",
    "    points = []\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        pred = (output >= threshold).int()\n",
    "\n",
    "        data = np.split(data.cpu().numpy(), len(data))\n",
    "        loss = np.split(loss.cpu().numpy(), len(data))\n",
    "        pred = np.split(pred.cpu().numpy(), len(data))\n",
    "        target = np.split(target.cpu().numpy(), len(data))\n",
    "        points.extend(zip(data, loss, pred, target))\n",
    "\n",
    "        if num is not None and len(points) > num:\n",
    "            break\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    model_factory,\n",
    "    num_epochs,\n",
    "    optimizer_kwargs,\n",
    "    threshold,\n",
    "    train_loader, \n",
    "    val_loader,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # ===== Data Loading =====\n",
    "    train_loader = train_loader()\n",
    "    val_loader = val_loader()\n",
    "\n",
    "    # ===== Model, Optimizer and Criterion =====\n",
    "    model = model_factory()\n",
    "    model = model.to(device=device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_kwargs)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(len(train_loader.dataset) * num_epochs) // train_loader.batch_size,\n",
    "    ) #USE THIS SCHEDULER\n",
    "    # ===== Train Model =====\n",
    "    lr_history = []\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, lrs = train_epoch(\n",
    "            model, optimizer, scheduler, criterion, train_loader, epoch, device, threshold\n",
    "        )\n",
    "        train_loss_history.extend(train_loss)\n",
    "        train_acc_history.extend(train_acc)\n",
    "        lr_history.extend(lrs)\n",
    "\n",
    "        val_loss, val_acc = validate(model, device, val_loader, criterion, threshold)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "    # ===== Plot training curves =====\n",
    "    n_train = len(train_acc_history)\n",
    "    t_train = num_epochs * np.arange(n_train) / n_train\n",
    "    t_val = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(6.4 * 3, 4.8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(t_train, train_acc_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_acc_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(t_train, train_loss_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_loss_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(t_train, lr_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "    # ===== Plot low/high loss predictions on validation set =====\n",
    "    points = get_predictions(\n",
    "        model,\n",
    "        device,\n",
    "        val_loader,\n",
    "        partial(torch.nn.BCEWithLogitsLoss, reduction=\"none\"),\n",
    "        threshold\n",
    "    )\n",
    "    points.sort(key=lambda x: x[1])\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for k in range(5):\n",
    "        plt.subplot(2, 5, k + 1)\n",
    "        plt.imshow(points[k][0][0, 0], cmap=\"gray\")\n",
    "        plt.title(f\"true={int(points[k][3])} pred={int(points[k][2])}\")\n",
    "        plt.subplot(2, 5, 5 + k + 1)\n",
    "        plt.imshow(points[-k - 1][0][0, 0], cmap=\"gray\")\n",
    "        plt.title(f\"true={int(points[-k-1][3])} pred={int(points[-k-1][2])}\")\n",
    "\n",
    "    return sum(train_acc) / len(train_acc), val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_kwargs = dict(lr=5e-4, weight_decay=1e-3)\n",
    "\n",
    "run_training(model,\n",
    "    num_epochs = 5,\n",
    "    optimizer_kwargs = optimizer_kwargs,\n",
    "    threshold = 0.5,\n",
    "    train_loader = train_loader, \n",
    "    val_loader = val_loader,\n",
    "    device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esmfold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
